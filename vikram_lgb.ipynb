{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_final.csv', index_col='Id')\n",
    "df_ult = pd.read_csv('data/test_final.csv', index_col='Id')\n",
    "\n",
    "X = df.drop('Y', axis='columns').values\n",
    "y = df['Y'].values\n",
    "\n",
    "X_ult = df_ult.values\n",
    "\n",
    "scale_pos_weight = len(y[y == 0])/len(y[y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003391</td>\n",
       "      <td>-0.004638</td>\n",
       "      <td>0.014199</td>\n",
       "      <td>-0.004121</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.031858</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>-0.001946</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>-0.008155</td>\n",
       "      <td>-0.009366</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>-0.002102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>-0.003391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026442</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>-0.012170</td>\n",
       "      <td>0.009720</td>\n",
       "      <td>-0.011067</td>\n",
       "      <td>-0.006072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003320</td>\n",
       "      <td>-0.004262</td>\n",
       "      <td>0.010071</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>-0.003790</td>\n",
       "      <td>0.006677</td>\n",
       "      <td>0.018798</td>\n",
       "      <td>-0.008867</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>0.011586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>-0.004638</td>\n",
       "      <td>0.026442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>-0.002410</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>-0.007852</td>\n",
       "      <td>-0.002839</td>\n",
       "      <td>-0.000573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.008306</td>\n",
       "      <td>-0.001172</td>\n",
       "      <td>-0.002480</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>-0.000812</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>-0.002820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>0.014199</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>-0.006871</td>\n",
       "      <td>0.038115</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>-0.008797</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.066988</td>\n",
       "      <td>-0.001787</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>-0.005255</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.003628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5</th>\n",
       "      <td>-0.004121</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>-0.002410</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>-0.009440</td>\n",
       "      <td>-0.003951</td>\n",
       "      <td>-0.001085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002781</td>\n",
       "      <td>-0.001335</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.010716</td>\n",
       "      <td>-0.008261</td>\n",
       "      <td>-0.004549</td>\n",
       "      <td>-0.007948</td>\n",
       "      <td>-0.001700</td>\n",
       "      <td>-0.004421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6</th>\n",
       "      <td>-0.003148</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>-0.006871</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.013056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.015064</td>\n",
       "      <td>-0.005578</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>-0.002715</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>-0.001689</td>\n",
       "      <td>-0.006430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7</th>\n",
       "      <td>0.001298</td>\n",
       "      <td>-0.012170</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.038115</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>-0.011992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012774</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>-0.005491</td>\n",
       "      <td>0.015218</td>\n",
       "      <td>0.017307</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>-0.007056</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.000610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8</th>\n",
       "      <td>0.021653</td>\n",
       "      <td>0.009720</td>\n",
       "      <td>-0.007852</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>-0.009440</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008102</td>\n",
       "      <td>-0.007583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019469</td>\n",
       "      <td>-0.008580</td>\n",
       "      <td>-0.184269</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.166054</td>\n",
       "      <td>-0.000723</td>\n",
       "      <td>-0.015716</td>\n",
       "      <td>0.006589</td>\n",
       "      <td>-0.005096</td>\n",
       "      <td>-0.004944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f9</th>\n",
       "      <td>-0.000203</td>\n",
       "      <td>-0.011067</td>\n",
       "      <td>-0.002839</td>\n",
       "      <td>-0.008797</td>\n",
       "      <td>-0.003951</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>-0.008102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.011958</td>\n",
       "      <td>-0.000545</td>\n",
       "      <td>-0.017294</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>-0.009139</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>-0.001326</td>\n",
       "      <td>-0.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f10</th>\n",
       "      <td>-0.012698</td>\n",
       "      <td>-0.006072</td>\n",
       "      <td>-0.000573</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>-0.001085</td>\n",
       "      <td>0.013056</td>\n",
       "      <td>-0.011992</td>\n",
       "      <td>-0.007583</td>\n",
       "      <td>-0.001562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>-0.006509</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>-0.006443</td>\n",
       "      <td>-0.005890</td>\n",
       "      <td>-0.006236</td>\n",
       "      <td>-0.005660</td>\n",
       "      <td>-0.000736</td>\n",
       "      <td>0.012982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f11</th>\n",
       "      <td>0.006446</td>\n",
       "      <td>-0.003517</td>\n",
       "      <td>-0.002480</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>-0.009862</td>\n",
       "      <td>-0.008838</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>-0.007601</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>-0.005119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010386</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.008112</td>\n",
       "      <td>-0.008551</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>-0.001837</td>\n",
       "      <td>-0.001635</td>\n",
       "      <td>-0.006013</td>\n",
       "      <td>-0.001692</td>\n",
       "      <td>0.004997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f12</th>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>-0.000812</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>-0.000870</td>\n",
       "      <td>0.014473</td>\n",
       "      <td>-0.003130</td>\n",
       "      <td>-0.010722</td>\n",
       "      <td>-0.004022</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015798</td>\n",
       "      <td>-0.001241</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>-0.003646</td>\n",
       "      <td>-0.004741</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>-0.005353</td>\n",
       "      <td>-0.005680</td>\n",
       "      <td>-0.000480</td>\n",
       "      <td>-0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f13</th>\n",
       "      <td>0.008371</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>-0.011013</td>\n",
       "      <td>-0.003947</td>\n",
       "      <td>-0.007024</td>\n",
       "      <td>0.091076</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>-0.004797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003131</td>\n",
       "      <td>0.010655</td>\n",
       "      <td>-0.153325</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.149742</td>\n",
       "      <td>-0.003837</td>\n",
       "      <td>-0.005747</td>\n",
       "      <td>-0.000905</td>\n",
       "      <td>-0.002714</td>\n",
       "      <td>0.004196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f14</th>\n",
       "      <td>0.003478</td>\n",
       "      <td>-0.002164</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.005489</td>\n",
       "      <td>-0.013923</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.004554</td>\n",
       "      <td>-0.004890</td>\n",
       "      <td>0.011748</td>\n",
       "      <td>-0.007054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>-0.005906</td>\n",
       "      <td>0.014349</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.013998</td>\n",
       "      <td>-0.007585</td>\n",
       "      <td>-0.009547</td>\n",
       "      <td>-0.001239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f15</th>\n",
       "      <td>0.004943</td>\n",
       "      <td>-0.003320</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>-0.002781</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>-0.012774</td>\n",
       "      <td>-0.019469</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002317</td>\n",
       "      <td>-0.119782</td>\n",
       "      <td>-0.009962</td>\n",
       "      <td>0.025024</td>\n",
       "      <td>-0.002332</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>-0.005482</td>\n",
       "      <td>0.006557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f16</th>\n",
       "      <td>0.029470</td>\n",
       "      <td>-0.004262</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>-0.001335</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.008580</td>\n",
       "      <td>0.011958</td>\n",
       "      <td>-0.006509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035102</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>-0.004557</td>\n",
       "      <td>0.010950</td>\n",
       "      <td>-0.002447</td>\n",
       "      <td>-0.006266</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.002618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f17</th>\n",
       "      <td>0.031858</td>\n",
       "      <td>0.010071</td>\n",
       "      <td>-0.008306</td>\n",
       "      <td>0.066988</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>-0.184269</td>\n",
       "      <td>-0.000545</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119782</td>\n",
       "      <td>0.035102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>-0.007941</td>\n",
       "      <td>-0.007229</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>0.009929</td>\n",
       "      <td>-0.004470</td>\n",
       "      <td>0.007165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f18</th>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>-0.001172</td>\n",
       "      <td>-0.001787</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.015064</td>\n",
       "      <td>-0.005491</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>-0.017294</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009962</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.023746</td>\n",
       "      <td>-0.010794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f19</th>\n",
       "      <td>-0.001946</td>\n",
       "      <td>-0.003790</td>\n",
       "      <td>-0.002480</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.010716</td>\n",
       "      <td>-0.005578</td>\n",
       "      <td>0.015218</td>\n",
       "      <td>0.166054</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>-0.006443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025024</td>\n",
       "      <td>-0.004557</td>\n",
       "      <td>-0.007941</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>-0.009134</td>\n",
       "      <td>-0.005799</td>\n",
       "      <td>-0.002440</td>\n",
       "      <td>-0.010936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f20</th>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.006677</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>-0.008261</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>0.017307</td>\n",
       "      <td>-0.000723</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>-0.005890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002332</td>\n",
       "      <td>0.010950</td>\n",
       "      <td>-0.007229</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005553</td>\n",
       "      <td>0.008851</td>\n",
       "      <td>-0.001702</td>\n",
       "      <td>-0.001864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f21</th>\n",
       "      <td>-0.008155</td>\n",
       "      <td>0.018798</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>-0.005255</td>\n",
       "      <td>-0.004549</td>\n",
       "      <td>-0.002715</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>-0.015716</td>\n",
       "      <td>-0.009139</td>\n",
       "      <td>-0.006236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>-0.002447</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>-0.009134</td>\n",
       "      <td>-0.005553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>-0.001115</td>\n",
       "      <td>-0.005213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f22</th>\n",
       "      <td>-0.009366</td>\n",
       "      <td>-0.008867</td>\n",
       "      <td>-0.000812</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>-0.007948</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>-0.007056</td>\n",
       "      <td>0.006589</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>-0.005660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>-0.006266</td>\n",
       "      <td>0.009929</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>-0.005799</td>\n",
       "      <td>0.008851</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>0.016978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f23</th>\n",
       "      <td>0.006847</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.001700</td>\n",
       "      <td>-0.001689</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>-0.005096</td>\n",
       "      <td>-0.001326</td>\n",
       "      <td>-0.000736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005482</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>-0.004470</td>\n",
       "      <td>0.023746</td>\n",
       "      <td>-0.002440</td>\n",
       "      <td>-0.001702</td>\n",
       "      <td>-0.001115</td>\n",
       "      <td>-0.000342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f24</th>\n",
       "      <td>-0.002102</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>-0.002820</td>\n",
       "      <td>-0.003628</td>\n",
       "      <td>-0.004421</td>\n",
       "      <td>-0.006430</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>-0.004944</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>-0.010794</td>\n",
       "      <td>-0.010936</td>\n",
       "      <td>-0.001864</td>\n",
       "      <td>-0.005213</td>\n",
       "      <td>0.016978</td>\n",
       "      <td>-0.001168</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1        f2        f3        f4        f5        f6        f7  \\\n",
       "f1   1.000000 -0.003391 -0.004638  0.014199 -0.004121 -0.003148  0.001298   \n",
       "f2  -0.003391  1.000000  0.026442  0.006225  0.006678  0.002049 -0.012170   \n",
       "f3  -0.004638  0.026442  1.000000  0.000483 -0.002410 -0.000694  0.000510   \n",
       "f4   0.014199  0.006225  0.000483  1.000000  0.009693 -0.006871  0.038115   \n",
       "f5  -0.004121  0.006678 -0.002410  0.009693  1.000000  0.008260  0.005845   \n",
       "f6  -0.003148  0.002049 -0.000694 -0.006871  0.008260  1.000000  0.006861   \n",
       "f7   0.001298 -0.012170  0.000510  0.038115  0.005845  0.006861  1.000000   \n",
       "f8   0.021653  0.009720 -0.007852  0.017708 -0.009440  0.001224  0.000741   \n",
       "f9  -0.000203 -0.011067 -0.002839 -0.008797 -0.003951  0.001379  0.002666   \n",
       "f10 -0.012698 -0.006072 -0.000573 -0.002021 -0.001085  0.013056 -0.011992   \n",
       "f11  0.006446 -0.003517 -0.002480  0.005120 -0.009862 -0.008838  0.003479   \n",
       "f12  0.003792  0.005779 -0.000812  0.004193 -0.000870  0.014473 -0.003130   \n",
       "f13  0.008371  0.002434 -0.002071  0.012451 -0.011013 -0.003947 -0.007024   \n",
       "f14  0.003478 -0.002164  0.003601  0.005489 -0.013923  0.007330  0.004554   \n",
       "f15  0.004943 -0.003320 -0.002022  0.000530 -0.002781  0.009897 -0.012774   \n",
       "f16  0.029470 -0.004262 -0.000046  0.005781 -0.001335  0.007094  0.000034   \n",
       "f17  0.031858  0.010071 -0.008306  0.066988  0.004467  0.001291  0.019590   \n",
       "f18 -0.000300  0.011750 -0.001172 -0.001787  0.000422  0.015064 -0.005491   \n",
       "f19 -0.001946 -0.003790 -0.002480  0.007615  0.010716 -0.005578  0.015218   \n",
       "f20  0.002467  0.006677  0.000133  0.006043 -0.008261 -0.002008  0.017307   \n",
       "f21 -0.008155  0.018798  0.003409 -0.005255 -0.004549 -0.002715  0.002906   \n",
       "f22 -0.009366 -0.008867 -0.000812  0.008059 -0.007948  0.006413 -0.007056   \n",
       "f23  0.006847 -0.001677 -0.000196  0.000067 -0.001700 -0.001689  0.001074   \n",
       "f24 -0.002102  0.011586 -0.002820 -0.003628 -0.004421 -0.006430  0.000610   \n",
       "\n",
       "           f8        f9       f10  ...       f15       f16       f17  \\\n",
       "f1   0.021653 -0.000203 -0.012698  ...  0.004943  0.029470  0.031858   \n",
       "f2   0.009720 -0.011067 -0.006072  ... -0.003320 -0.004262  0.010071   \n",
       "f3  -0.007852 -0.002839 -0.000573  ... -0.002022 -0.000046 -0.008306   \n",
       "f4   0.017708 -0.008797 -0.002021  ...  0.000530  0.005781  0.066988   \n",
       "f5  -0.009440 -0.003951 -0.001085  ... -0.002781 -0.001335  0.004467   \n",
       "f6   0.001224  0.001379  0.013056  ...  0.009897  0.007094  0.001291   \n",
       "f7   0.000741  0.002666 -0.011992  ... -0.012774  0.000034  0.019590   \n",
       "f8   1.000000 -0.008102 -0.007583  ... -0.019469 -0.008580 -0.184269   \n",
       "f9  -0.008102  1.000000 -0.001562  ...  0.002999  0.011958 -0.000545   \n",
       "f10 -0.007583 -0.001562  1.000000  ...  0.001688 -0.006509  0.006255   \n",
       "f11 -0.007601  0.008261 -0.005119  ...  0.010386  0.002799  0.008112   \n",
       "f12 -0.010722 -0.004022 -0.000463  ...  0.015798 -0.001241  0.010549   \n",
       "f13  0.091076  0.000127 -0.004797  ... -0.003131  0.010655 -0.153325   \n",
       "f14 -0.004890  0.011748 -0.007054  ...  0.000191  0.006389  0.005140   \n",
       "f15 -0.019469  0.002999  0.001688  ...  1.000000 -0.002317 -0.119782   \n",
       "f16 -0.008580  0.011958 -0.006509  ... -0.002317  1.000000  0.035102   \n",
       "f17 -0.184269 -0.000545  0.006255  ... -0.119782  0.035102  1.000000   \n",
       "f18  0.003078 -0.017294 -0.004871  ... -0.009962 -0.001086  0.005611   \n",
       "f19  0.166054 -0.000429 -0.006443  ...  0.025024 -0.004557 -0.007941   \n",
       "f20 -0.000723  0.005832 -0.005890  ... -0.002332  0.010950 -0.007229   \n",
       "f21 -0.015716 -0.009139 -0.006236  ...  0.004654 -0.002447 -0.000305   \n",
       "f22  0.006589  0.000264 -0.005660  ... -0.000909 -0.006266  0.009929   \n",
       "f23 -0.005096 -0.001326 -0.000736  ... -0.005482  0.003021 -0.004470   \n",
       "f24 -0.004944 -0.001005  0.012982  ...  0.006557  0.002618  0.007165   \n",
       "\n",
       "          f18       f19       f20       f21       f22       f23       f24  \n",
       "f1  -0.000300 -0.001946  0.002467 -0.008155 -0.009366  0.006847 -0.002102  \n",
       "f2   0.011750 -0.003790  0.006677  0.018798 -0.008867 -0.001677  0.011586  \n",
       "f3  -0.001172 -0.002480  0.000133  0.003409 -0.000812 -0.000196 -0.002820  \n",
       "f4  -0.001787  0.007615  0.006043 -0.005255  0.008059  0.000067 -0.003628  \n",
       "f5   0.000422  0.010716 -0.008261 -0.004549 -0.007948 -0.001700 -0.004421  \n",
       "f6   0.015064 -0.005578 -0.002008 -0.002715  0.006413 -0.001689 -0.006430  \n",
       "f7  -0.005491  0.015218  0.017307  0.002906 -0.007056  0.001074  0.000610  \n",
       "f8   0.003078  0.166054 -0.000723 -0.015716  0.006589 -0.005096 -0.004944  \n",
       "f9  -0.017294 -0.000429  0.005832 -0.009139  0.000264 -0.001326 -0.001005  \n",
       "f10 -0.004871 -0.006443 -0.005890 -0.006236 -0.005660 -0.000736  0.012982  \n",
       "f11 -0.008551  0.001052 -0.001837 -0.001635 -0.006013 -0.001692  0.004997  \n",
       "f12 -0.003646 -0.004741  0.002017 -0.005353 -0.005680 -0.000480 -0.000572  \n",
       "f13  0.011311  0.149742 -0.003837 -0.005747 -0.000905 -0.002714  0.004196  \n",
       "f14 -0.005906  0.014349  0.006008  0.013998 -0.007585 -0.009547 -0.001239  \n",
       "f15 -0.009962  0.025024 -0.002332  0.004654 -0.000909 -0.005482  0.006557  \n",
       "f16 -0.001086 -0.004557  0.010950 -0.002447 -0.006266  0.003021  0.002618  \n",
       "f17  0.005611 -0.007941 -0.007229 -0.000305  0.009929 -0.004470  0.007165  \n",
       "f18  1.000000  0.001969  0.001873  0.011628  0.000405  0.023746 -0.010794  \n",
       "f19  0.001969  1.000000  0.003784 -0.009134 -0.005799 -0.002440 -0.010936  \n",
       "f20  0.001873  0.003784  1.000000 -0.005553  0.008851 -0.001702 -0.001864  \n",
       "f21  0.011628 -0.009134 -0.005553  1.000000  0.009824 -0.001115 -0.005213  \n",
       "f22  0.000405 -0.005799  0.008851  0.009824  1.000000 -0.000342  0.016978  \n",
       "f23  0.023746 -0.002440 -0.001702 -0.001115 -0.000342  1.000000 -0.001168  \n",
       "f24 -0.010794 -0.010936 -0.001864 -0.005213  0.016978 -0.001168  1.000000  \n",
       "\n",
       "[24 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Y', axis='columns').corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ind(mask): return [index for index, mask_ele in enumerate(mask) if mask_ele==True]\n",
    "\n",
    "def get_best_ind(importances, start=7, number=5):\n",
    "    ranked_features = sorted(range(len(importances)), key=lambda i: importances[i], reverse=True)\n",
    "    return [ranked_features[:i] for i in range(start, start + number)]\n",
    "\n",
    "def get_best_features(model, data, step=1):\n",
    "    rfecv = RFECV(estimator=model, step=step, cv=StratifiedKFold(5), scoring='roc_auc', n_jobs=-1)\n",
    "    return rfecv.fit(data, y)\n",
    "\n",
    "def get_clf():\n",
    "    return lgbm.LGBMClassifier(n_estimators=500,\n",
    "                               learning_rate=0.1, \n",
    "                               boosting_type='goss', \n",
    "                               max_depth=5, \n",
    "                               num_leaves=33,\n",
    "                               objective='binary', \n",
    "                               scale_pos_weight=scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_params(params, dec):\n",
    "    new_params = {}\n",
    "    new_params['n_estimators'] = [round(params['n_estimators'] + np.ceil(dec)), \n",
    "                                  round(params['n_estimators'] - np.ceil(dec))]\n",
    "    new_params['learning_rate'] = [params['learning_rate'] + 0.001 * dec, \n",
    "                                   params['learning_rate'] - 0.001 * dec]\n",
    "    new_params['n_estimators'] = [round(params['num_leaves'] + np.ceil(0.05 * dec)), \n",
    "                                  round(params['num_leaves'] - np.ceil(0.05 * dec))]\n",
    "    new_params['reg_alpha'] = [params['reg_alpha'] * (1 + (0.02 * dec)), \n",
    "                               params['reg_alpha'] * (1 - (0.02 * dec))]\n",
    "    new_params['reg_lambda'] = [params['reg_lambda'] + (0.05 * dec), \n",
    "                                params['reg_lambda'] - (0.05 * dec)]\n",
    "    return new_params\n",
    "\n",
    "start_var_param = [{\n",
    "    'n_estimators':                  500,\n",
    "    'learning_rate':                 0.1, \n",
    "    'num_leaves':                    33, \n",
    "    'reg_alpha':                     0.001, \n",
    "    'reg_lambda':                    1, \n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_param = {\n",
    "    'boosting_type':                 'goss', \n",
    "    'max_depth':                     5, \n",
    "    'objective':                     'binary', \n",
    "    'scale_pos_weight':              scale_pos_weight,\n",
    "    'n_jobs':                        -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = clfs[2].fit(X, y)\n",
    "pd.Series(clf.feature_importances_, index=list(range(X.shape[1]))).plot.bar(color='steelblue', figsize=(16, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 7, 12, 13, 14, 15]\n",
      "[0, 3, 7, 12, 13, 14, 15, 18, 22]\n",
      "[0, 3, 7, 11, 12, 13, 14, 15, 16, 18, 22]\n"
     ]
    }
   ],
   "source": [
    "rankings = get_best_features(clfs[2], X).ranking_\n",
    "\n",
    "print(get_ind(np.isin(rankings, [1])))\n",
    "print(get_ind(np.isin(rankings, [1, 2, 3])))\n",
    "print(get_ind(np.isin(rankings, [1, 2, 3, 4, 5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'feature_fraction': 0.38, 'min_child_weight': 1e-07, 'n_estimators': 945, 'seed': 55}.\n",
      "Best auc score is 0.8961743884754645.\n",
      "Best parameters {'feature_fraction': 0.38, 'min_child_weight': 1e-07, 'n_estimators': 945, 'seed': 121}.\n",
      "Best auc score is 0.8963934561372057.\n"
     ]
    }
   ],
   "source": [
    "var_param = {'min_child_samples':             20,\n",
    "             'learning_rate':                 0.1, \n",
    "             'num_leaves':                    31,\n",
    "             'reg_alpha':                     0.000659,\n",
    "             'reg_lambda':                    0.9}\n",
    "\n",
    "def do_tune(tun_param, feats):\n",
    "    grid = GridSearchCV(lgbm.LGBMClassifier(**fix_param, **var_param), \n",
    "                        tun_param, \n",
    "                        cv=StratifiedKFold(5), \n",
    "                        scoring='roc_auc', \n",
    "                        n_jobs=-1)\n",
    "    \n",
    "    grid.fit(X[:, feats], y)\n",
    "    \n",
    "    print(f'Best parameters {grid.best_params_}.')\n",
    "    print(f'Best auc score is {grid.best_score_}.')\n",
    "    \n",
    "    clfs.append(grid.best_estimator_)\n",
    "\n",
    "clfs = []\n",
    "tun_param = [{'n_estimators':                  [910], # 895 to 915\n",
    "              'min_child_weight':              [9e-7],\n",
    "              'feature_fraction':              [0.25]}] #0.24 to 0.26\n",
    "do_tune(tun_param, [3, 6, 7, 12, 13, 14, 15, 16, 18, 21])\n",
    "\n",
    "tun_param = [{'n_estimators':                  [980], # 1000 to 970\n",
    "              'min_child_weight':              [1e-7], \n",
    "              'feature_fraction':              [0.05]}] # 0.06 to 0.07\n",
    "do_tune(tun_param, [0, 3, 7, 12, 13, 14, 15])\n",
    "\n",
    "tun_param = [{'n_estimators':                  [845], # 844 to 847\n",
    "              'min_child_weight':              [1e-7], \n",
    "              'feature_fraction':              [0.23],  # 0.2 to 0.25\n",
    "              'seed':                          list(range(100))}]\n",
    "do_tune(tun_param, [1, 3, 6, 7, 12, 13, 14, 15, 16, 18, 23])\n",
    "\n",
    "tun_param = [{'n_estimators':                  [945], # 955 to 940\n",
    "              'min_child_weight':              [1e-7], \n",
    "              'feature_fraction':              [0.38], # 0.41 to 0.35\n",
    "              'seed':                          list(range(100))}]\n",
    "do_tune(tun_param, [0, 1, 3, 6, 7, 12, 13, 14, 15, 16, 18, 23])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Re-training...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Writing...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Done.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "req_rows = 16384\n",
    "sealed_feats = []\n",
    "\n",
    "display('Re-training...')\n",
    "preds_dfs = []\n",
    "for feats, clf in zip(sealed_feats, clfs):\n",
    "    clf.fit(X[:, feats], y)\n",
    "    preds_dfs.append(pd.DataFrame(clf.predict_proba(X_ult[:, feats])[:, 1], \n",
    "                          index=list(range(req_rows, req_rows*2 + 1)), \n",
    "                          columns=['Y']))\n",
    "\n",
    "display('Writing...')\n",
    "for idx, df in enumerate(preds_dfs):\n",
    "    df.index.name = 'Id'\n",
    "    df.to_csv(f'submission_26_{idx}.csv', float_format='%.20f')\n",
    "display('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
