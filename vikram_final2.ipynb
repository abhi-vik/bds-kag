{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomTreesEmbedding\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_final.csv', index_col='Id')\n",
    "df_ult = pd.read_csv('data/test_final.csv', index_col='Id')\n",
    "\n",
    "X = df.drop('Y', axis='columns').values\n",
    "y = df['Y'].values\n",
    "\n",
    "X_ult = df_ult.values\n",
    "\n",
    "scale_pos_weight = len(y[y == 0])/len(y[y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, y=True):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['f8-f19'] = df['f8'] - df['f19']\n",
    "    df_copy['f8-f13'] = df['f8'] - df['f13']\n",
    "    df_copy['f17-f4'] = df['f17'] - df['f4']\n",
    "    df_copy['f4-f7'] = df['f4'] - df['f7']\n",
    "    df_copy['f13-f19'] = df['f13'] - df['f19']\n",
    "    df_copy['f8wf13wf19'] = PCA(n_components=1).fit_transform(df[['f8', 'f13', 'f19']])\n",
    "    return df_copy.drop('Y', axis='columns') if y else df_copy\n",
    "\n",
    "# selected_cols = ['f14', 'f13', 'f15', 'f4', 'f8wf13wf19', 'f4-f7', 'f16', 'f17', 'f19', 'f1', 'f8-f19']\n",
    "selected_cols = ['f1', 'f4', 'f8', 'f13', 'f14', 'f15', 'f16', 'f17', 'f8-f19', 'f8-f13', 'f17-f4', 'f4-f7', 'f8wf13wf19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = transform(df)[selected_cols]\n",
    "test = transform(df_ult, y=False)[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to test\n",
    "# train, test, y, y_test = train_test_split(train, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "SEED = 0\n",
    "NFOLDS = 5\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=SEED, params=None):\n",
    "        if seed is not None:\n",
    "            params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict_proba(x)[:, 1]\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train, y_train)):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'class_weight': 'balanced', \n",
    "    'criterion': 'gini', \n",
    "    'max_depth': None, \n",
    "    'n_estimators': 1000, \n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'class_weight': 'balanced', \n",
    "    'criterion': 'entropy', \n",
    "    'max_depth': None, \n",
    "    'n_estimators': 1000, \n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate' : 1\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'loss': 'exponential', \n",
    "    'max_depth': 5, \n",
    "    'n_estimators': 500, \n",
    "}\n",
    "\n",
    "lgb_params = {\n",
    "    'boosting_type':                 'goss', \n",
    "    'metric':                        'auc', \n",
    "    'objective':                     'binary', \n",
    "    'scale_pos_weight':              scale_pos_weight, \n",
    "    'n_jobs':                        -1, \n",
    "    'n_estimators':                  1000, \n",
    "    'learning_rate':                 0.1, \n",
    "    'colsample_bytree':              0.01, \n",
    "    'reg_alpha':                     0, \n",
    "    'reg_lambda':                    0.89995, \n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'objective':                      'binary:logistic', \n",
    "    'booster':                        'gbtree',\n",
    "    'tree_method':                    'exact', \n",
    "    'eval_metric':                    'auc',\n",
    "    'scale_pos_weight':               scale_pos_weight,\n",
    "    'n_jobs':                         -1,\n",
    "    'max_depth':                      5, \n",
    "    'learning_rate':                  0.1, \n",
    "    'n_estimators':                   1000, \n",
    "    'colsample_bylevel':              0.03, \n",
    "    'colsample_bynode':               0.86\n",
    "}\n",
    "\n",
    "xgb2_params = {\n",
    "    'objective':                      'binary:logistic', \n",
    "    'booster':                        'gbtree',\n",
    "    'tree_method':                    'exact', \n",
    "    'eval_metric':                    'auc',\n",
    "#     'scale_pos_weight':               scale_pos_weight,\n",
    "    'n_jobs':                         -1,\n",
    "    'n_estimators':                   260, \n",
    "    'learning_rate':                  0.0075, \n",
    "    'max_depth':                      4, \n",
    "    'reg_alpha':                      0, \n",
    "    'reg_lambda':                     0.9, \n",
    "    'random_state':                   0,\n",
    "    'colsample_bylevel':              0.03, \n",
    "    'colsample_bynode':               0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "# knc64 = SklearnHelper(clf=KNeighborsClassifier, seed=None, params={'n_neighbors': 64})\n",
    "# knc128 = SklearnHelper(clf=KNeighborsClassifier, seed=None, params={'n_neighbors': 128})\n",
    "# knc256 = SklearnHelper(clf=KNeighborsClassifier, seed=None, params={'n_neighbors': 256})\n",
    "lgbc = SklearnHelper(clf=lgbm.LGBMClassifier, seed=SEED, params=lgb_params)\n",
    "xgbc = SklearnHelper(clf=xgb.XGBClassifier, seed=SEED, params=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y\n",
    "x_train = train.values\n",
    "x_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test)\n",
    "print('.')\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test)\n",
    "print('.')\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test)\n",
    "print('.')\n",
    "gb_oof_train, gb_oof_test = get_oof(gb, x_train, y_train, x_test)\n",
    "print('.')\n",
    "# knc64_oof_train, knc64_oof_test = get_oof(knc64, x_train, y_train, x_test)\n",
    "# print('.')\n",
    "# knc128_oof_train, knc128_oof_test = get_oof(knc128, x_train, y_train, x_test)\n",
    "# print('.')\n",
    "# knc256_oof_train, knc256_oof_test = get_oof(knc256, x_train, y_train, x_test)\n",
    "# print('.')\n",
    "lgbc_oof_train, lgbc_oof_test = get_oof(lgbc, x_train, y_train, x_test)\n",
    "print('.')\n",
    "xgbc_oof_train, xgbc_oof_test = get_oof(xgbc, x_train, y_train, x_test)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 7, 12, 13, 14, 15, 16, 24, 25, 26, 27, 29]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ind(mask): return [index for index, mask_ele in enumerate(mask) if mask_ele==True]\n",
    "def get_best_features(model, data, step=1):\n",
    "    rfecv = RFECV(estimator=model, step=step, cv=StratifiedKFold(5), scoring='roc_auc', n_jobs=-1)\n",
    "    rfecv.fit(data, df['Y'].values)\n",
    "\n",
    "    return get_ind(rfecv.ranking_ == 1)\n",
    "\n",
    "best = get_best_features(xgb.XGBClassifier(**xgb_params), transform(df).values)\n",
    "best\n",
    "# pd.Series(clf.feature_importances_, index=list(range(X.shape[1]))).plot.bar(color='steelblue', figsize=(16, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "alts = ['f1', 'f4', 'f8', 'f13', 'f14', 'f15', 'f16', 'f17', 'f8-f19', 'f8-f13', 'f17-f4', 'f4-f7', 'f8wf13wf19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f1',\n",
       " 'f4',\n",
       " 'f8',\n",
       " 'f13',\n",
       " 'f14',\n",
       " 'f15',\n",
       " 'f16',\n",
       " 'f17',\n",
       " 'f8-f19',\n",
       " 'f8-f13',\n",
       " 'f17-f4',\n",
       " 'f4-f7',\n",
       " 'f8wf13wf19']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ind_to_name(df, idx): return df.columns[idx].tolist()\n",
    "ind_to_name(transform(df), best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>GradientBoost</th>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>XGBClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.501002</td>\n",
       "      <td>0.998659</td>\n",
       "      <td>0.990588</td>\n",
       "      <td>0.894865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.968</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.500514</td>\n",
       "      <td>0.951903</td>\n",
       "      <td>0.699376</td>\n",
       "      <td>0.559421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.500458</td>\n",
       "      <td>0.997719</td>\n",
       "      <td>0.993427</td>\n",
       "      <td>0.831691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.747</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.500413</td>\n",
       "      <td>0.892027</td>\n",
       "      <td>0.776301</td>\n",
       "      <td>0.370943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.501064</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.969721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RandomForest  ExtraTrees  AdaBoost  GradientBoost  LGBMClassifier  \\\n",
       "0         0.937       0.982  0.501002       0.998659        0.990588   \n",
       "1         0.968       0.972  0.500514       0.951903        0.699376   \n",
       "2         0.939       0.936  0.500458       0.997719        0.993427   \n",
       "3         0.747       0.743  0.500413       0.892027        0.776301   \n",
       "4         0.928       0.986  0.501064       0.999917        0.999913   \n",
       "\n",
       "   XGBClassifier  \n",
       "0       0.894865  \n",
       "1       0.559421  \n",
       "2       0.831691  \n",
       "3       0.370943  \n",
       "4       0.969721  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame( {\n",
    "    'RandomForest': rf_oof_train.ravel(),\n",
    "    'ExtraTrees': et_oof_train.ravel(),\n",
    "    'AdaBoost': ada_oof_train.ravel(),\n",
    "    'GradientBoost': gb_oof_train.ravel(),\n",
    "#     '64NeighbourClassifier': knc64_oof_train.ravel(),\n",
    "#     '128NeighbourClassifier': knc128_oof_train.ravel(),\n",
    "#     '256NeighbourClassifier': knc256_oof_train.ravel(),\n",
    "    'LGBMClassifier': lgbc_oof_train.ravel(),\n",
    "    'XGBClassifier': xgbc_oof_train.ravel()\n",
    "})\n",
    "base_predictions_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8916954671230289"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_train = np.concatenate(( \n",
    "    et_oof_train, \n",
    "    rf_oof_train, \n",
    "    ada_oof_train, \n",
    "    gb_oof_train, \n",
    "#     knc64_oof_train, \n",
    "#     knc128_oof_train, \n",
    "#     knc256_oof_train, \n",
    "    lgbc_oof_train, \n",
    "    xgbc_oof_train\n",
    "), axis=1)\n",
    "\n",
    "x2_test = np.concatenate((\n",
    "    et_oof_test, \n",
    "    rf_oof_test, \n",
    "    ada_oof_test, \n",
    "    gb_oof_test, \n",
    "#     knc64_oof_test, \n",
    "#     knc128_oof_test, \n",
    "#     knc256_oof_test, \n",
    "    lgbc_oof_test, \n",
    "    xgbc_oof_test\n",
    "), axis=1)\n",
    "\n",
    "x2_train = np.append(x2_train.T, x_train.T, axis=0).T\n",
    "x2_test = np.append(x2_test.T, x_test.T, axis=0).T\n",
    "\n",
    "lgbc2 = SklearnHelper(clf=lgbm.LGBMClassifier, seed=SEED, params=lgb_params)\n",
    "xgbc2 = SklearnHelper(clf=xgb.XGBClassifier, seed=SEED, params=xgb_params)\n",
    "\n",
    "lgbc2_oof_train, lgbc2_oof_test = get_oof(lgbc2, x2_train, y_train, x2_test)\n",
    "xgbc2_oof_train, xgbc2_oof_test = get_oof(xgbc2, x2_train, y_train, x2_test)\n",
    "\n",
    "roc_auc_score(y_test, xgbc2_oof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8882746026277869"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, xgbc_oof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8936050022040221"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, lgbc_oof_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.values\n",
    "# test = test.values\n",
    "train, x_cal, y, y_cal = train_test_split(train, y, test_size=0.2)\n",
    "\n",
    "first_layer_models = [\n",
    "    RandomForestClassifier(**rf_params),\n",
    "    ExtraTreesClassifier(**et_params),\n",
    "    AdaBoostClassifier(**ada_params),\n",
    "    GradientBoostingClassifier(**gb_params),\n",
    "    lgbm.LGBMClassifier(**lgb_params),\n",
    "    xgb.XGBClassifier(**xgb_params)\n",
    "]\n",
    "\n",
    "[model.fit(train, y) for model in first_layer_models]\n",
    "\n",
    "first_layer_train_preds = [model.predict_proba(train)[:, 1] for model in first_layer_models]\n",
    "first_layer_test_preds = [model.predict_proba(test)[:, 1] for model in first_layer_models]\n",
    "first_layer_cal = [model.predict_proba(x_cal)[:, 1] for model in first_layer_models]\n",
    "\n",
    "second_layer_train = np.append(np.array(first_layer_train_preds), train.T, axis=0).T\n",
    "second_layer_test = np.append(np.array(first_layer_test_preds), test.T, axis=0).T\n",
    "second_layer_cal = np.append(np.array(first_layer_cal), x_cal.T, axis=0).T\n",
    "\n",
    "second_layer_model = xgb.XGBClassifier(**xgb2_params)\n",
    "second_layer_model.fit(second_layer_train, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "calibrator = CalibratedClassifierCV(second_layer_model, method='sigmoid', cv='prefit')\n",
    "calibrator.fit(second_layer_cal, y_cal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_predictions = calibrator.predict_proba(second_layer_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_rows = 16384\n",
    "\n",
    "result = pd.DataFrame(last_predictions, \n",
    "                      index=list(range(req_rows, req_rows*2 + 1)), \n",
    "                      columns=['Y'])\n",
    "\n",
    "result.index.name = 'Id'\n",
    "result.to_csv(f'submission_29_3.csv', float_format='%.20f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'learning_rate': 0.02, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0}.\n",
      "Best auc score is 0.890822749511769.\n"
     ]
    }
   ],
   "source": [
    "const_params = {\n",
    "    'objective':                      'binary:logistic', \n",
    "    'booster':                        'gbtree',\n",
    "    'tree_method':                    'exact', \n",
    "    'eval_metric':                    'auc',\n",
    "    'scale_pos_weight':               scale_pos_weight,\n",
    "    'n_jobs':                         -1\n",
    "}\n",
    "\n",
    "tuning_parameters = {    \n",
    "    'n_estimators':                   [300], \n",
    "    'learning_rate':                  [0.02], \n",
    "    'max_depth':                      [2], \n",
    "    'random_state': [0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(xgb.XGBClassifier(**const_params), \n",
    "                          tuning_parameters, \n",
    "                          cv=skfold, \n",
    "                          scoring='roc_auc', \n",
    "                          n_jobs=-1)\n",
    "\n",
    "grid.fit(x2_train, y)\n",
    "\n",
    "print(f'Best parameters {grid.best_params_}.')\n",
    "print(f'Best auc score is {grid.best_score_}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'learning_rate': 0.02, 'max_depth': 2, 'n_estimators': 250}.\n",
      "Best auc score is 0.8906617395164347.\n"
     ]
    }
   ],
   "source": [
    "fix_param = {\n",
    "    'boosting_type':                 'goss', \n",
    "    'metric':                        'auc', \n",
    "    'objective':                     'binary', \n",
    "    'scale_pos_weight':              scale_pos_weight, \n",
    "    'n_jobs':                        -1\n",
    "}\n",
    "\n",
    "now_param = {\n",
    "    'n_estimators':                  [250], \n",
    "    'learning_rate':                 [0.02], \n",
    "    'max_depth':                     [2], \n",
    "#     'early_stopping_rounds'\n",
    "#     'reg_alpha':                     [0], \n",
    "#     'reg_lambda':                    [0.89995, 1, 0], \n",
    "#     'seed': list(range(60, 62)),\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(lgbm.LGBMClassifier(**fix_param), \n",
    "                          now_param, \n",
    "                          cv=StratifiedKFold(5), \n",
    "                          scoring='roc_auc', \n",
    "                          n_jobs=-1)\n",
    "\n",
    "grid.fit(x2_train, y)\n",
    "\n",
    "print(f'Best parameters {grid.best_params_}.')\n",
    "print(f'Best auc score is {grid.best_score_}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'colsample_bylevel': 0.03, 'colsample_bynode': 0.8, 'learning_rate': 0.0075, 'max_depth': 4, 'n_estimators': 260, 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 0.9}.\n",
      "Best auc score is 0.8895835881594708.\n"
     ]
    }
   ],
   "source": [
    "const_params = {\n",
    "    'objective':                      'binary:logistic', \n",
    "    'booster':                        'gbtree',\n",
    "    'tree_method':                    'exact', \n",
    "    'eval_metric':                    'auc',\n",
    "    'scale_pos_weight':               scale_pos_weight,\n",
    "    'n_jobs':                         -1\n",
    "}\n",
    "\n",
    "tuning_parameters = {    \n",
    "    'n_estimators':                   [255, 260], \n",
    "    'learning_rate':                  [0.0075], \n",
    "    'max_depth':                      [4], \n",
    "    'reg_alpha':                      [0], \n",
    "    'reg_lambda':                     [0.9], \n",
    "    'random_state':                   [0],\n",
    "    'colsample_bylevel':              [0.03], \n",
    "    'colsample_bynode':               [0.8]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(xgb.XGBClassifier(**const_params), \n",
    "                          tuning_parameters, \n",
    "                          cv=kf, \n",
    "                          scoring='roc_auc', \n",
    "                          n_jobs=-1)\n",
    "\n",
    "grid.fit(x2_train, y_train)\n",
    "\n",
    "print(f'Best parameters {grid.best_params_}.')\n",
    "print(f'Best auc score is {grid.best_score_}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
