{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Data Science\n",
    "\n",
    "Abhilash Vikram Gupta\n",
    "\n",
    "https://www.kaggle.com/c/mis382n-fall-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_final.csv', index_col='Id')\n",
    "df_ult = pd.read_csv('data/test_final.csv', index_col='Id')\n",
    "\n",
    "X = df.drop('Y', axis='columns').values\n",
    "y = df['Y'].values\n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "X_ult = df_ult.values\n",
    "\n",
    "scale_pos_weight = len(y[y == 0])/len(y[y == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "done using forward, backward and a model's feature_importances_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ind(mask): return [index for index, mask_ele in enumerate(mask) if mask_ele==True]\n",
    "\n",
    "def get_best_ind(importances, start=7, number=5):\n",
    "    ranked_features = sorted(range(len(importances)), key=lambda i: importances[i], reverse=True)\n",
    "    return [ranked_features[:i] for i in range(start, start + number)]\n",
    "\n",
    "def get_clf():\n",
    "#     return lgbm.LGBMClassifier(n_estimators=400,\n",
    "#                                learning_rate=0.1, \n",
    "#                                boosting_type='goss', \n",
    "#                                max_depth=5, \n",
    "#                                num_leaves=33,\n",
    "#                                objective='binary', \n",
    "#                                scale_pos_weight=scale_pos_weight)\n",
    "    return xgb.XGBClassifier(max_depth=5, \n",
    "                             learning_rate=0.1, \n",
    "                             n_estimators=750, \n",
    "                             objective='binary:logistic', \n",
    "                             tree_method='auto', \n",
    "                             eval_metric='auc', \n",
    "                             n_jobs=-1, \n",
    "                             reg_alpha=0.001,\n",
    "                             scale_pos_weight=scale_pos_weight)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_features(model, data, step=1):\n",
    "    rfecv = RFECV(estimator=model, step=step, cv=StratifiedKFold(5), scoring='roc_auc', n_jobs=-1)\n",
    "    rfecv.fit(data, y)\n",
    "\n",
    "    return get_ind(rfecv.ranking_ == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 6, 7, 12, 13, 14, 15, 16, 18, 23]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_features(get_clf(), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = get_clf().fit(X, y)\n",
    "pd.Series(clf.feature_importances_, index=list(range(X.shape[1]))).plot.bar(color='steelblue', figsize=(16, 7));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "Based on weighted average and intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats_to_try = get_best_ind(clf.feature_importances_)\n",
    "feats_to_try = [\n",
    "#     [3, 6, 7, 12, 13, 14, 15],\n",
    "    [3, 6, 7, 12, 13, 14, 15, 16, 18, 21],\n",
    "    [3, 6, 7, 12, 13, 14, 15, 16, 18],\n",
    "    [1, 3, 6, 7, 12, 13, 14, 15, 16, 18, 23] # was best last time\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "and collection of best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 742, 'objective': 'binary:logistic', 'reg_alpha': 0.0011, 'reg_lambda': 1.2, 'tree_method': 'auto'}.\n",
      "Best auc score is 0.8860748069839841.\n",
      "Best parameters {'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 728, 'objective': 'binary:logistic', 'reg_alpha': 0.0011, 'reg_lambda': 1.2, 'tree_method': 'auto'}.\n",
      "Best auc score is 0.8831812165578737.\n",
      "Best parameters {'booster': 'gbtree', 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 728, 'objective': 'binary:logistic', 'reg_alpha': 0.0011, 'reg_lambda': 0.9, 'tree_method': 'auto'}.\n",
      "Best auc score is 0.8850524446357293.\n"
     ]
    }
   ],
   "source": [
    "# params = {\n",
    "# 'task':'train',\n",
    "# 'numleaves': 31, 'objective': 'multiclass', 'numclass':10,\n",
    "# 'mindatainleaf': 100, 'learningrate': 0.05,\n",
    "# 'featurefraction': 0.85, 'baggingfraction': 0.85,\n",
    "# 'baggingfreq': 2, 'metric': 'multierror',\n",
    "# 'maxbin':128, 'numthreads': 32\n",
    "# }\n",
    "\n",
    "# lgb_train = lgb.Dataset(X_train, \n",
    "#                         label=y_train,\n",
    "#                         feature_name=feature_names, \n",
    "#                         categorical_feature=categorical_features)\n",
    "\n",
    "# tuning_parameters = [{'n_estimators':                  [500], \n",
    "#                       'boosting_type':                 ['goss'],\n",
    "#                       'learning_rate':                 [0.1], \n",
    "#                       'max_depth':                     [5],\n",
    "#                       'num_leaves':                    [33],\n",
    "#                       'objective':                     ['binary'],\n",
    "#                       'reg_alpha':                     np.logspace(-3, -2, 2),\n",
    "#                       'reg_lambda':                    [1],\n",
    "#                       'scale_pos_weight':              [scale_pos_weight]}]\n",
    "\n",
    "tuning_parameters = [{'max_depth':                      [5], \n",
    "                      'learning_rate':                  [0.1], \n",
    "                      'n_estimators':                   [728, 735, 742], \n",
    "                      'objective':                      ['binary:logistic'], \n",
    "                      'booster':                        ['gbtree'],\n",
    "                      'tree_method':                    ['auto'], \n",
    "                      'reg_alpha':                      [0.0011], \n",
    "                      'reg_lambda':                     [0.9, 1.2]}]\n",
    "\n",
    "clfs = []\n",
    "for feats in feats_to_try:\n",
    "\n",
    "    grid = GridSearchCV(xgb.XGBClassifier(n_jobs=-1, eval_metric='auc', scale_pos_weight=scale_pos_weight), \n",
    "                        tuning_parameters, \n",
    "                        cv=StratifiedKFold(5), \n",
    "                        scoring='roc_auc', \n",
    "                        n_jobs=-1)\n",
    "    \n",
    "    grid.fit(X[:, feats], y)\n",
    "    \n",
    "    print(f'Best parameters {grid.best_params_}.')\n",
    "    print(f'Best auc score is {grid.best_score_}.')\n",
    "    \n",
    "    clfs.append(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation\n",
    "\n",
    "of submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Re-training...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Writing...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Done.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "req_rows = 16384\n",
    "\n",
    "display('Re-training...')\n",
    "preds_dfs = []\n",
    "for feats, clf in zip(feats_to_try, clfs):\n",
    "    clf.fit(X[:, feats], y)\n",
    "    preds_dfs.append(pd.DataFrame(clf.predict_proba(X_ult[:, feats])[:, 1], \n",
    "                          index=list(range(req_rows, req_rows*2 + 1)), \n",
    "                          columns=['Y']))\n",
    "\n",
    "display('Writing...')\n",
    "for idx, df in enumerate(preds_dfs):\n",
    "    df.index.name = 'Id'\n",
    "    df.to_csv(f'submission_24_{idx}.csv')\n",
    "display('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ind_to_name(df, idx): return df.columns[idx].tolist()\n",
    "\n",
    "def generate_train(dataframe, model):\n",
    "    train_dataframe = dataframe.drop('Y', axis='columns')\n",
    "    labels = dataframe['Y']\n",
    "    \n",
    "    feature_ratings = model.fit(train_dataframe.values, labels).feature_importances_\n",
    "    first, second, third = get_best_ind(feature_ratings, 3, 1)[0]\n",
    "    first_name, second_name, third_name = indices_to_names(train_dataframe, [first, second, third])\n",
    "    \n",
    "    train_dataframe[first_name + '*1.5'] = train_dataframe[first_name] ** 1.5\n",
    "    train_dataframe[first_name + '*2'] = train_dataframe[first_name] ** 2\n",
    "    \n",
    "    relevant_columns = train_dataframe[[first_name, second_name, third_name]].values\n",
    "    scaled = StandardScaler().fit_transform(relevant_columns)\n",
    "    fused = PCA(n_components=1).fit_transform(scaled[:, 1:]).ravel()\n",
    "    \n",
    "    train_dataframe[first_name + '+fused'] = scaled[:, 0] + fused\n",
    "    train_dataframe[first_name + '-fused'] = scaled[:, 0] - fused\n",
    "    \n",
    "    return train_dataframe\n",
    "\n",
    "def alter_params(params, dec):\n",
    "    new_params = {}\n",
    "    new_params['n_estimators'] = [round(params['n_estimators'] + np.ceil(dec/5)), \n",
    "                                  params['n_estimators'],\n",
    "                                  round(params['n_estimators'] - np.ceil(dec/5))]\n",
    "    new_params['reg_alpha'] = [params['reg_alpha'] * (1 + (0.005 * dec)),\n",
    "                               params['reg_alpha'],\n",
    "                               params['reg_alpha'] * (1 - (0.005 * dec))]\n",
    "    new_params['reg_lambda'] = [params['reg_lambda'] + (0.001 * dec), \n",
    "                                params['reg_lambda'], \n",
    "                                params['reg_lambda'] - (0.001 * dec)]\n",
    "    return new_params\n",
    "\n",
    "results_dataframe = pd.DataFrame(columns=['score', 'params', 'features', 'dec'])\n",
    "\n",
    "const_params = {\n",
    "    'max_depth':                      5, \n",
    "    'learning_rate':                  0.1, \n",
    "    'objective':                      'binary:logistic', \n",
    "    'booster':                        'gbtree',\n",
    "    'tree_method':                    'exact', \n",
    "    'eval_metric':                    'auc',\n",
    "    'scale_pos_weight':               scale_pos_weight,\n",
    "    'n_jobs':                         -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_iteratively(params, dec):\n",
    "    if dec < 1:\n",
    "        return\n",
    "    \n",
    "    print(f'Variation decay factor {dec}.')\n",
    "    \n",
    "    print('Feature tuning...')\n",
    "    # new_train = generate_train(df, model)\n",
    "    new_train = df.drop('Y', axis='columns')\n",
    "    \n",
    "    old_model = xgb.XGBClassifier(**const_params, **params)\n",
    "    new_feats = ind_to_name(new_train, get_best_features(old_model, new_train.values))\n",
    "\n",
    "    variable_params = alter_params(params, dec)\n",
    "    print(variable_params)\n",
    "\n",
    "    print('Param tuning...')\n",
    "    grid = GridSearchCV(xgb.XGBClassifier(**const_params), \n",
    "                        variable_params, \n",
    "                        cv=StratifiedKFold(5), \n",
    "                        scoring='roc_auc', \n",
    "                        n_jobs=-1)\n",
    "\n",
    "    grid.fit(new_train[new_feats].values, y)\n",
    "\n",
    "    print(f'Best parameters {grid.best_params_}.')\n",
    "    print(f'Best auc score is {grid.best_score_}.')\n",
    "\n",
    "#     results_dataframe = results_dataframe.append({'score': grid.best_score_, \n",
    "#                                                   'params': grid.best_params_, \n",
    "#                                                   'features': new_feats, \n",
    "#                                                   'dec': dec}, ignore_index=True)\n",
    "#     results_dataframe.to_csv('results.csv')\n",
    "\n",
    "    with open('results.csv','a') as f:\n",
    "        f.write('\\n, '.join([str(dec), str(grid.best_score_), str(grid.best_params_), str(new_feats)]))\n",
    "\n",
    "    tune_iteratively(grid.best_params_, dec - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5.\n",
      "Feature tuning...\n",
      "{'n_estimators': [709.0, 708, 707.0], 'reg_alpha': [0.0006764999999999999, 0.00066, 0.0006435], 'reg_lambda': [0.805, 0.8, 0.795]}\n",
      "Param tuning...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/abhivik/.local/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/home/abhivik/.local/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/abhivik/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 600, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/abhivik/.local/lib/python3.6/site-packages/joblib/parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/abhivik/.local/lib/python3.6/site-packages/joblib/parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/home/abhivik/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 516, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/abhivik/.local/lib/python3.6/site-packages/xgboost/sklearn.py\", line 732, in fit\n    callbacks=callbacks)\n  File \"/home/abhivik/.local/lib/python3.6/site-packages/xgboost/training.py\", line 216, in train\n    xgb_model=xgb_model, callbacks=callbacks)\n  File \"/home/abhivik/.local/lib/python3.6/site-packages/xgboost/training.py\", line 62, in _train_internal\n    for i in range(start_iteration, num_boost_round):\nTypeError: 'numpy.float64' object cannot be interpreted as an integer\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-6a93b1b11ca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m tune_iteratively({'n_estimators': 708,\n\u001b[1;32m      2\u001b[0m                   \u001b[0;34m'reg_alpha'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.00066\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                   'reg_lambda': 0.8}, 5)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-174-989b615c5677>\u001b[0m in \u001b[0;36mtune_iteratively\u001b[0;34m(params, dec)\u001b[0m\n\u001b[1;32m     22\u001b[0m                         n_jobs=-1)\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_feats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Best parameters {grid.best_params_}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "tune_iteratively({'n_estimators': 708,\n",
    "                  'reg_alpha': 0.00066, \n",
    "                  'reg_lambda': 0.8}, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
